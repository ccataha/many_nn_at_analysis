{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library to read excel data\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "\n",
    "    # Read csv data\n",
    "    print(\"---  Reading csv data            ---\")\n",
    "    dirpath = \"resources/\"\n",
    "    filename = \"kddcup99_csv.csv\"\n",
    "    kddCup = pd.read_csv(dirpath+filename)\n",
    "\n",
    "    # Split data in 70% 15% 15%\n",
    "    print(\"---  Split data in train, validate and test  ---\")\n",
    "    trainingData, validateData, testData = np.split(kddCup.sample(frac=1), [int(.6*len(kddCup)), int(.8*len(kddCup))])\n",
    "\n",
    "    print(\"---  TrainingData 70% length = \" + str(len(trainingData))+\" ---\")\n",
    "    print(\"---  ValidateData 15% lenght = \" + str(len(validateData))+\" ---\")\n",
    "    print(\"---  TestData 15% length     = \" + str(len(testData))+\" ---\")\n",
    "    return trainingData, validateData, testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definePredictionModel():\n",
    "    print(\"\\n\\n---  Creating RNN Model                       ---\")\n",
    "    # Define new Model for rnn\n",
    "    model = tf.keras.models.Sequential()\n",
    "    # Adding model first layer with 41 features (42 - label feature)\n",
    "    model.add(tf.keras.layers.SimpleRNN(41))\n",
    "    # Adding Hidden Layers\n",
    "    # Adding Activation sigmoid on Hidden Layers\n",
    "    model.add(tf.keras.layers.Dense(units=80,activation='sigmoid',name=\"dense_1\"))\n",
    "    model.add(tf.keras.layers.Dense(units=160,activation='sigmoid',name=\"dense_2\"))\n",
    "    model.add(tf.keras.layers.Dense(units=240,activation='sigmoid',name=\"dense_3\"))\n",
    "    model.add(tf.keras.layers.Dense(units=160,activation='sigmoid',name=\"dense_4\"))\n",
    "    model.add(tf.keras.layers.Dense(units=80,activation='sigmoid',name=\"dense_5\"))\n",
    "    # Adding output layer (normal(0) - anomaly(1))\n",
    "    model.add(tf.keras.layers.Dense(units=2,activation='softmax',name=\"predictions\"))\n",
    "    # Adding learning rate and metrics\n",
    "    model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001),\n",
    "                loss=tf.keras.losses.mean_squared_error,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSummary(result,validationData):\n",
    "    printStats(getStats(validationData,result))\n",
    "\n",
    "def getStats(real,predicted):\n",
    "    numClasses = real.shape[1]\n",
    "    stats = []\n",
    "    for i in range(0,numClasses):\n",
    "        stats.append([])\n",
    "        for j in range(0,numClasses):\n",
    "            stats[i].append(0)\n",
    "    for i in range(0,len(predicted)):\n",
    "        p = np.argmax(predicted[i])\n",
    "        r = np.argmax(real[i])\n",
    "        stats[p][r]+=1\n",
    "    metrics = {}\n",
    "    for i in range(0,numClasses):\n",
    "        tp = stats[i][i]\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for j in range(0,numClasses):\n",
    "            if (i!=j):\n",
    "                fp += stats[i][j]\n",
    "                fn += stats[j][i]\n",
    "        if (tp+fp) > 0: precision = tp/(tp+fp)\n",
    "        else: precision = -1\n",
    "        if (tp+fn) > 0: recall = tp/(tp+fn)\n",
    "        else: recall = -1\n",
    "        if precision >= 0 and recall >= 0 and (precision+recall>0): f1 = 2*precision*recall/(precision+recall)        \n",
    "        else: f1 = -1\n",
    "        metrics[i]= {'precision': precision,\n",
    "                     'recall': recall,\n",
    "                     'f1': f1 }\n",
    "    return stats,metrics\n",
    "\n",
    "def printStats(stats):\n",
    "    cm,m=stats\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(\"P \\ R\\tnormal\\tanomaly\")\n",
    "    print(\"normal\\t\"+str(cm[0][0])+\"\\t\"+str(cm[0][1]))\n",
    "    print(\"anomaly\\t\"+str(cm[1][0])+\"\\t\"+str(cm[1][1]))\n",
    "    print(\"\")\n",
    "    print(\"Metrics\")\n",
    "    print(\"Conexion\\tPrecision\\tRecall\\tF-1\")\n",
    "    print(\"normal\\t\"+str(m[0]['precision'])+\"\\t\"+str(m[0]['recall'])+\"\\t\"+str(m[0][\"f1\"]))\n",
    "    print(\"anomaly\\t\"+str(m[1]['precision'])+\"\\t\"+str(m[1]['recall'])+\"\\t\"+str(m[1][\"f1\"]))\n",
    "    print(\"\\n\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeColumn(data):\n",
    "    arrayData = np.array(data)\n",
    "    normalizedData = preprocessing.normalize(arrayData)\n",
    "    return normalizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformColumn(column, array, default):\n",
    "    rows = list(set(column.tolist()))\n",
    "    for row in rows:\n",
    "        try:\n",
    "            column = column.replace([row],array[row])\n",
    "        except KeyError:\n",
    "            column = column.replace([row],default)\n",
    "    return column\n",
    "# Library to transform data\n",
    "def transformDataLabel(kddCup):\n",
    "    # Transform Text data to number\n",
    "    protocolTypeLabel = {'icmp': 0, 'tcp': 1, 'udp': 2}\n",
    "    kddCup[\"protocol_type\"] = transformColumn(kddCup[\"protocol_type\"],protocolTypeLabel,2)\n",
    "    # print(kddCup[\"protocol_type\"])\n",
    "    flagLabel = {'OTH': 0, 'REJ': 1, 'RSTO': 2, 'RSTOS0': 3, 'RSTR': 4, 'S0': 5, 'S1': 6, 'S2': 7, 'S3': 8, 'SF': 9, 'SH': 10}\n",
    "    kddCup[\"flag\"] = transformColumn(kddCup[\"flag\"],flagLabel,1)\n",
    "    # print(kddCup[\"flag\"])\n",
    "    serviceLabel = {'auth': 0, 'bgp': 1, 'courier': 2, 'csnet_ns': 3, 'ctf': 4,'daytime': 5, 'discard': 6,\n",
    "               'domain': 7, 'domain_u': 8, 'echo': 9, 'eco_i': 10, 'ecr_i': 11, 'efs': 12,\n",
    "               'exec': 13, 'finger': 14, 'ftp': 15, 'ftp_data': 16, 'gopher': 17, 'hostnames': 18,\n",
    "               'http': 19, 'http_443': 20, 'imap4': 21, 'IRC': 22, 'iso_tsap': 23, 'klogin': 24, 'kshell': 25,\n",
    "               'ldap': 26, 'link': 27, 'login': 28, 'mtp': 29, 'name': 30, 'netbios_dgm': 31, 'netbios_ns': 32,\n",
    "               'netbios_ssn': 33, 'netstat': 34, 'nnsp': 35, 'nntp': 36, 'ntp_u': 37, 'other': 38,\n",
    "               'pm_dump': 39, 'pop_2': 40, 'pop_3': 41, 'printer': 42, 'private': 43, 'red_i': 44,\n",
    "               'remote_job': 45, 'rje': 46, 'shell': 47, 'smtp': 48, 'sql_net': 49, 'ssh': 50,\n",
    "               'sunrpc': 51, 'supdup': 52, 'systat': 53, 'telnet': 54, 'tftp_u': 55, 'tim_i': 56, 'time': 57,\n",
    "               'urh_i': 58, 'urp_i': 59, 'uucp': 60, 'uucp_path': 61, 'vmnet': 62, 'whois': 63,\n",
    "               'X11': 64, 'Z39_50': 65}\n",
    "    kddCup[\"service\"] = transformColumn(kddCup[\"service\"],serviceLabel,19)          \n",
    "    transformLabel = {'normal': 0}\n",
    "    kddCup[\"label\"] = transformColumn(kddCup[\"label\"],transformLabel,1)\n",
    "    # print(kddCup[\"label\"])\n",
    "    return kddCup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(epochs,  model, trainingData, validateData):\n",
    "    # Training Model\n",
    "    print(\"\\n\\n---  Training model                           ---\")\n",
    "    print(\"---  Transform and Normalize Training Data    ---\")\n",
    "    print(\"---  Training                                 ---\")\n",
    "    TrainingDataX, TrainingDataY = transformData(trainingData)\n",
    "    validateDataX, validateDataY = transformData(validateData)\n",
    "    model.fit(TrainingDataX,TrainingDataY,epochs=epochs,batch_size=25,shuffle=True,\n",
    "    validation_data=(validateDataX,validateDataY))\n",
    "    \n",
    "    print(\"\\n\\n---  Training Results:                            ---\")\n",
    "    results = model.predict(TrainingDataX)\n",
    "    model_results.showSummary(TrainingDataY,results)\n",
    "\n",
    "    print(\"\\n\\n---  Validate Results:                            ---\")\n",
    "    results = model.predict(validateDataX)\n",
    "    model_results.showSummary(validateDataY,results)\n",
    "    return model\n",
    "\n",
    "def evaluateModel(model, testData):\n",
    "    print(\"\\n\\n---  Evaluate model                           ---\")\n",
    "    print(\"---  Transform and Normalize Evaluate Data       ---\")\n",
    "    testDataX, testDataY = transformData(testData)\n",
    "    # Validate Model\n",
    "    print(\"\\n\\n---  Evaluate Results:                            ---\")\n",
    "    results = model.evaluate(testDataX)\n",
    "    # model_results.showSummary(testDataY,results)\n",
    "    print(results)\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    # Validate Model\n",
    "    print(\"\\n\\n---  Predict                                    ---\")\n",
    "    results = model.predict(testDataX[:10])\n",
    "    print(\"---  Results:                               ---\")\n",
    "    model_results.showSummary(testDataY,results)\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    return model\n",
    "\n",
    "def transformData(data):\n",
    "    # Transform text to number\n",
    "    print(\"---  Transform text to number                 ---\")\n",
    "    data = transformDataLabel(data)\n",
    "    # Split and remove columns\n",
    "    print(\"---  Remove unused columns                    ---\")\n",
    "    kddCupY = data[\"label\"]\n",
    "    kddCupY = kddCupY.to_numpy()   \n",
    "    # Assing category data shape \n",
    "    kddCupY = keras.utils.to_categorical(kddCupY,2)\n",
    "    kddCupX = data\n",
    "    kddCupX.pop(\"label\")\n",
    "    kddCupX = kddCupX.to_numpy()\n",
    "    # Normalize data\n",
    "    print(\"---  Normalize Colum Data                     ---\")\n",
    "    normalizeDataX = normalizeColumn(kddCupX)\n",
    "    # Reshape\n",
    "    print(\"---  Reshaping Data                           ---\")\n",
    "    normalizeDataX = normalizeDataX.reshape((normalizeDataX.shape[0],normalizeDataX.shape[1],-1))\n",
    "    return normalizeDataX, kddCupY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  Starting Neural Network                  ---\n",
      "-------------------------------------------------\n",
      "---  Reading csv data            ---\n",
      "---  Split data in train, validate and test  ---\n",
      "---  TrainingData 70% length = 296412 ---\n",
      "---  ValidateData 15% lenght = 98804 ---\n",
      "---  TestData 15% length     = 98804 ---\n",
      "\n",
      "\n",
      "---  Creating RNN Model                       ---\n",
      "-------------------------------------------------\n",
      "\n",
      "\n",
      "---  Training model                           ---\n",
      "---  Transform and Normalize Training Data    ---\n",
      "---  Training                                 ---\n",
      "---  Transform text to number                 ---\n",
      "---  Remove unused columns                    ---\n",
      "---  Normalize Colum Data                     ---\n",
      "---  Reshaping Data                           ---\n",
      "---  Transform text to number                 ---\n",
      "---  Remove unused columns                    ---\n",
      "---  Normalize Colum Data                     ---\n",
      "---  Reshaping Data                           ---\n",
      "Epoch 1/3\n",
      "11857/11857 [==============================] - 92s 8ms/step - loss: 0.1528 - accuracy: 0.8121 - val_loss: 0.1529 - val_accuracy: 0.8113\n",
      "Epoch 2/3\n",
      "11857/11857 [==============================] - 86s 7ms/step - loss: 0.1522 - accuracy: 0.8126 - val_loss: 0.1532 - val_accuracy: 0.8113\n",
      "Epoch 3/3\n",
      "11857/11857 [==============================] - 112s 9ms/step - loss: 0.1522 - accuracy: 0.8126 - val_loss: 0.1530 - val_accuracy: 0.8113\n",
      "\n",
      "\n",
      "---  Training Results:                            ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aaee91f0f882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefinePredictionModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train and Validate Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidateData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0913175b6931>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(epochs, model, trainingData, validateData)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n---  Training Results:                            ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingDataX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmodel_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingDataY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n---  Validate Results:                            ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Program header\n",
    "print(\"---  Starting Neural Network                  ---\")\n",
    "print(\"-------------------------------------------------\")\n",
    "\n",
    "# Get Data\n",
    "trainingData, validateData, testData = readData()\n",
    "\n",
    "# Create Model Prediction\n",
    "model = definePredictionModel()\n",
    "# Train and Validate Model\n",
    "model = trainModel(3, model, trainingData, validateData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
